{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE6N3AWmMZ_-"
      },
      "outputs": [],
      "source": [
        "#!unzip src.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY9RYuLoL_wc"
      },
      "outputs": [],
      "source": [
        "!pip install python-chess==0.31.2\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL8XC08ZMix2"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_m5dNj-L_wd"
      },
      "outputs": [],
      "source": [
        "import chess\n",
        "import sys\n",
        "import torch\n",
        "import random\n",
        "from transformers import GPT2LMHeadModel, AutoModel\n",
        "sys.path.append(\"src\")\n",
        "from data_utils.chess_tokenizer import ChessTokenizer\n",
        "import chess.pgn as pgn\n",
        "import io\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x8ty39LL_wd"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Part 1\n",
        "# ----------------------------\n",
        "\n",
        "def read_pgn_file(file_path):\n",
        "    games = []\n",
        "    with open(file_path, \"r\") as pgn_file:\n",
        "        while True:\n",
        "            game = chess.pgn.read_game(pgn_file)\n",
        "            if game is None:\n",
        "                break\n",
        "            if(len(list(game.mainline_moves())) > 4):\n",
        "            #if (game.headers[\"Termination\"] == 'Normal'):\n",
        "                games.append(game[0])\n",
        "    return games\n",
        "\n",
        "def get_legal_moves(board):\n",
        "    legal_moves = set()\n",
        "    for move in board.legal_moves:\n",
        "        uci_move = board.uci(move)\n",
        "        legal_moves.add(uci_move)\n",
        "    return legal_moves\n",
        "\n",
        "\n",
        "def chop_game_at_random_point(pgn):\n",
        "    # Split the PGN string into individual moves\n",
        "    moves = pgn.split()\n",
        "    game_moves = [(re.sub(r'\\d+\\.', '', move).strip()) for move in moves]\n",
        "    # Determine the total number of moves\n",
        "    total_moves = len(game_moves)\n",
        "    # Ensure we have an even number of moves for simplicity\n",
        "    if total_moves % 2 != 0:\n",
        "        total_moves -= 1\n",
        "    # Randomly choose a point to chop, ensuring 50/50 white/black split\n",
        "    random_index = random.randint(7, total_moves - 1)\n",
        "    # Determine if the random point should be a white or black move\n",
        "    if random_index % 2 == 0:\n",
        "        chopped_game = ' '.join(moves[:random_index + 1])\n",
        "        _next_after_chop = ' '.join(moves[:random_index + 2])\n",
        "    else:\n",
        "        chopped_game = ' '.join(moves[:random_index + 2])\n",
        "        _next_after_chop = ' '.join(moves[:random_index + 3])\n",
        "\n",
        "    #_next_after_chop= moves[random_index+2]\n",
        "    return chopped_game, _next_after_chop\n",
        "\n",
        "def chop_game_before_final_moves(pgn):\n",
        "    moves = pgn.split()\n",
        "    #game_moves = [move for move in moves if not move[0].isdigit()]\n",
        "    game_moves = [(re.sub(r'\\d+\\.', '', move).strip()) for move in moves]\n",
        "    total_moves = len(game_moves)\n",
        "    if total_moves < 2 :\n",
        "        chopped_game = ' '.join(moves)\n",
        "        return 'skip'\n",
        "    else:\n",
        "        chopped_game = ' '.join(moves[:total_moves - 2])\n",
        "\n",
        "    return chopped_game\n",
        "\n",
        "\n",
        "def predict_move1(input_seq, tokenizer, model, n_tokens = 3):\n",
        "\n",
        "    game_prefix = [tokenizer.bos_token_id]\n",
        "    game_prefix_str = \"\"\n",
        "\n",
        "    game_prefix.extend(tokenizer.encode(input_seq, add_special_tokens=False, get_move_end_positions=False))\n",
        "    game_prefix_str += input_seq + \" \"\n",
        "\n",
        "    greedy_game_prefix = list(game_prefix)\n",
        "    prefix_tens = torch.tensor([greedy_game_prefix])\n",
        "    pred_move = \"\"\n",
        "\n",
        "    # default range is 3 tokens.\n",
        "    for idx in range(n_tokens):\n",
        "        logits = model(prefix_tens)[0]\n",
        "\n",
        "        # logits is a 3-dimensional tensor with the shape [batch_size, sequence_length, vocab_size].\n",
        "        # --> Extracting the logits for the last token.\n",
        "        last_token_logit = logits[0, -1, :]\n",
        "\n",
        "        token_idx = torch.argmax(last_token_logit).item()\n",
        "\n",
        "        current_token = tokenizer.decode_token(token_idx)\n",
        "        pred_move += current_token\n",
        "\n",
        "        if idx == 0 and current_token == tokenizer.eos_token:\n",
        "            break\n",
        "\n",
        "        greedy_game_prefix += [token_idx]\n",
        "        prefix_tens = torch.tensor([greedy_game_prefix])\n",
        "\n",
        "    if len(pred_move) == 6:\n",
        "        pred_move = pred_move[:4]\n",
        "\n",
        "    legal_moves = get_legal_moves(board)\n",
        "    if pred_move not in legal_moves:\n",
        "        print(\"ILLEGAL MOVE\")\n",
        "        print(f\"Legal moves: {legal_moves}\")\n",
        "\n",
        "    #print(f\"LM plays: {pred_move}\")\n",
        "    return pred_move\n",
        "\n",
        "def predict_half_legal_move1(input_seq, init_square):\n",
        "    # To make the model predict only 'half' of the move, add initial square of the next move\n",
        "    initial_square = init_square\n",
        "    b2 = input_seq + \" \" + initial_square\n",
        "\n",
        "    # and put n_tokens = 1\n",
        "    predict_move1(b2, n_tokens = 1)\n",
        "\n",
        "# probing to see if the game provides legal moves given the starting square\n",
        "def probing_legal_moves1(input_seq0, board, tokenizer, model):\n",
        "    legal_moves = get_legal_moves(board)\n",
        "    illegal_count = 0\n",
        "    for leg_move in legal_moves:\n",
        "\n",
        "        initial_square = leg_move[:2]\n",
        "        input_seq = input_seq0 + \" \" + initial_square\n",
        "\n",
        "        game_prefix = [tokenizer.bos_token_id]\n",
        "        game_prefix_str = \"\"\n",
        "\n",
        "        game_prefix.extend(tokenizer.encode(input_seq, add_special_tokens=False, get_move_end_positions=False))\n",
        "        game_prefix_str += input_seq + \" \"\n",
        "\n",
        "        greedy_game_prefix = list(game_prefix)\n",
        "        prefix_tens = torch.tensor([greedy_game_prefix])\n",
        "        pred_move = \"\"\n",
        "\n",
        "        for idx in range(1):\n",
        "            logits = model(prefix_tens)[0]\n",
        "\n",
        "            # logits is a 3-dimensional tensor with the shape [batch_size, sequence_length, vocab_size].\n",
        "            # --> Extracting the logits for the last token.\n",
        "            last_token_logit = logits[0, -1, :]\n",
        "\n",
        "            token_idx = torch.argmax(last_token_logit).item()\n",
        "\n",
        "            current_token = tokenizer.decode_token(token_idx)\n",
        "            pred_move += current_token\n",
        "\n",
        "            if idx == 0 and current_token == tokenizer.eos_token:\n",
        "                break\n",
        "\n",
        "            greedy_game_prefix += [token_idx]\n",
        "            prefix_tens = torch.tensor([greedy_game_prefix])\n",
        "\n",
        "            if len(pred_move) == 6:\n",
        "                pred_move = pred_move[:4]\n",
        "\n",
        "            pred_move = initial_square + pred_move\n",
        "            if pred_move not in legal_moves:\n",
        "            #print(\"ILLEGAL MOVE\")\n",
        "            #print(f\"Legal moves: {legal_moves}\")\n",
        "                illegal_count += 1\n",
        "\n",
        "            #print(f\"LM plays: {pred_move}\")\n",
        "\n",
        "    #print(f\"Ratio legal/total: {len(legal_moves)-illegal_count} / {len(legal_moves)}\")\n",
        "    return (len(legal_moves)-illegal_count), len(legal_moves)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjD7rlQ7L_we"
      },
      "outputs": [],
      "source": [
        "# Initialize the Model and the Tokenizer\n",
        "\n",
        "vocab_path = \"vocab.txt\"\n",
        "tokenizer = ChessTokenizer(vocab_path)\n",
        "model = GPT2LMHeadModel.from_pretrained('shtoshni/gpt2-chess-uci')\n",
        "\n",
        "ds = load_dataset(\"adamkarvonen/chess_sae_individual_games_filtered\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7SX6bM4L_we"
      },
      "outputs": [],
      "source": [
        "# Next move prediction given game sequence (PGN) and probing on legal moves given all starting squares.\n",
        "\n",
        "g = random.randint(0, 90000)\n",
        "a = ds['train']['text'][g][1:]\n",
        "b, c = chop_game_at_random_point(a)\n",
        "\n",
        "b1 = io.StringIO(b)\n",
        "game = pgn.read_game(b1)\n",
        "board = game.board()\n",
        "\n",
        "move_list = []\n",
        "for move in game.mainline_moves():\n",
        "    move_list.append(board.uci(move))\n",
        "    board.push(move)\n",
        "b1 = (\" \".join(move_list))\n",
        "\n",
        "print(\"PGN seq: \", b)\n",
        "print(\"UCI seq: \", b1)\n",
        "\n",
        "input_seq = b1\n",
        "predicted_move = predict_move1(input_seq, tokenizer, model)\n",
        "\n",
        "\n",
        "c1 = io.StringIO(c)\n",
        "game_c = pgn.read_game(c1)\n",
        "board_c = game_c.board()\n",
        "move_list_c = []\n",
        "for move_c in game_c.mainline_moves():\n",
        "    move_list_c.append(board_c.uci(move_c))\n",
        "    board_c.push(move_c)\n",
        "c1 = (\" \".join(move_list_c))\n",
        "\n",
        "\n",
        "print(f\"LM plays: {predicted_move}\")\n",
        "print(f\"(In the game it was: {c1[-4:]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQer2KN_L_we"
      },
      "outputs": [],
      "source": [
        "probed_legal_moves, tot = probing_legal_moves1(input_seq, board, tokenizer, model)\n",
        "print(\"correct legal moves over total legal moves:\", probed_legal_moves,\"/\", tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyLBDKCxL_we"
      },
      "outputs": [],
      "source": [
        "# testing legal moves predicting on 2k games from hf dataset\n",
        "# Ratio legal/total: 66028 / 67621 --> 97.64422294849233l\n",
        "\n",
        "def test_legal1():\n",
        "  l = 0\n",
        "  t = 0\n",
        "  g1 = 1\n",
        "  for g in range(0,2000):\n",
        "      b = chop_game_before_final_moves(ds['train']['text'][g][1:])\n",
        "      b1 = io.StringIO(b)\n",
        "      game = pgn.read_game(b1)\n",
        "      board = game.board()\n",
        "\n",
        "      move_list = []\n",
        "      for move in game.mainline_moves():\n",
        "          move_list.append(board.uci(move))\n",
        "          board.push(move)\n",
        "      b1 = (\" \".join(move_list))\n",
        "\n",
        "      input_seq = b1\n",
        "      legal, total = probing_legal_moves1(input_seq, board, tokenizer, model)\n",
        "      l = l + legal\n",
        "      t = t + total\n",
        "      print(f\"{g1} / {2000} ------- {legal} / {total} ---> Ratio legal/total: {l} / {t} --> {int(l/t*100)}%\")\n",
        "      g1 += 1\n",
        "\n",
        "  print(f\"Ratio legal/total: {l} / {t} --> {(l/t)*100}\")\n",
        "\n",
        "\n",
        "#--> uncomment to run test\n",
        "#test_legal1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIB0Vg7eL_we"
      },
      "outputs": [],
      "source": [
        "# testing legal moves predicting on my games on lichess (100% they are not on training set)\n",
        "# still around 97% legal moves ratio\n",
        "\n",
        "file_path = \"lichess_db1.pgn\"\n",
        "\n",
        "def test_legal2():\n",
        "  games = read_pgn_file(file_path)\n",
        "\n",
        "  l = 0\n",
        "  t = 0\n",
        "  g1 = 1\n",
        "  for g in range(len(games)):\n",
        "      b = chop_game_before_final_moves(str(games[g]))\n",
        "      b1 = io.StringIO(b)\n",
        "      game = pgn.read_game(b1)\n",
        "      board = game.board()\n",
        "\n",
        "      move_list = []\n",
        "      for move in game.mainline_moves():\n",
        "          move_list.append(board.uci(move))\n",
        "          board.push(move)\n",
        "      b1 = (\" \".join(move_list))\n",
        "\n",
        "      input_seq = b1\n",
        "      legal, total = probing_legal_moves1(input_seq, board, tokenizer, model)\n",
        "      l = l + legal\n",
        "      t = t + total\n",
        "      print(f\"{g1} / {2000} ------- {legal} / {total} ---> Ratio legal/total: {l} / {t} --> {int(l/t*100)}%\")\n",
        "      g1 += 1\n",
        "\n",
        "  print(f\"Ratio legal/total: {l} / {t} --> {(l/t)*100}\")\n",
        "\n",
        "#--> uncomment to run test\n",
        "#test_legal2()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ0q0vC2L_wf"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Part 2\n",
        "# ----------------------------\n",
        "# Attention: Heatmap Probing\n",
        "# ----------------------------\n",
        "\n",
        "\n",
        "# Initialize the Model and the Tokenizer\n",
        "vocab_path = \"vocab.txt\"\n",
        "tokenizer = ChessTokenizer(vocab_path)\n",
        "model = GPT2LMHeadModel.from_pretrained('shtoshni/gpt2-chess-uci')\n",
        "\n",
        "num_heads = model.config.num_attention_heads\n",
        "num_layers = len(model.transformer.h)\n",
        "#print(f\"Number of attention layers: {num_layers}\")\n",
        "#print(f\"Number of heads: {num_heads}\")\n",
        "\n",
        "ds = load_dataset(\"adamkarvonen/chess_sae_individual_games_filtered\")\n",
        "\n",
        "def get_model_output(input_sequence):\n",
        "    # Encode the input sequence\n",
        "    encoded = tokenizer.encode(input_sequence, add_special_tokens=False, get_move_end_positions=False)\n",
        "    # Convert to tensor and add batch dimension\n",
        "    inputs = torch.tensor([encoded]).long()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, output_attentions=True, output_hidden_states=True)\n",
        "    return outputs\n",
        "\n",
        "def visualize_attention0(input_sequence, layer=-1, head=0):\n",
        "    outputs = get_model_output(input_sequence)\n",
        "    attention = outputs.attentions[layer][0, head].cpu().numpy()\n",
        "\n",
        "    decoded_tokens = [tokenizer.decode_token(t) for t in tokenizer.encode(input_sequence, add_special_tokens=False, get_move_end_positions=False)]\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    #sns.heatmap(attention, cmap=\"YlOrRd\")   #--> this for token number\n",
        "    sns.heatmap(attention, cmap=\"YlOrRd\", xticklabels=decoded_tokens, yticklabels=decoded_tokens)\n",
        "    plt.title(f\"Attention weights for layer {layer+1}, head {head+1}\")\n",
        "    plt.xlabel(\"Key tokens\")\n",
        "    plt.ylabel(\"Query tokens\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def group_tokens(tokens):\n",
        "    \"\"\"Group tokens in pairs.\"\"\"\n",
        "    grouped_tokens = []\n",
        "    for i in range(0, len(tokens), 2):\n",
        "        if i + 1 < len(tokens):\n",
        "            grouped_tokens.append(f\"{tokens[i]}-{tokens[i + 1]}\")\n",
        "        else:\n",
        "            grouped_tokens.append(tokens[i])\n",
        "    return grouped_tokens\n",
        "\n",
        "def aggregate_attention(attention, group_size):\n",
        "    \"\"\"Aggregate attention weights by summing over grouped tokens.\"\"\"\n",
        "    num_tokens = attention.shape[0]\n",
        "    num_groups = (num_tokens + group_size - 1) // group_size\n",
        "\n",
        "    aggregated_attention = np.zeros((num_groups, num_groups))\n",
        "\n",
        "    for i in range(num_groups):\n",
        "        for j in range(num_groups):\n",
        "            start_i, end_i = i * group_size, min((i + 1) * group_size, num_tokens)\n",
        "            start_j, end_j = j * group_size, min((j + 1) * group_size, num_tokens)\n",
        "            aggregated_attention[i, j] = np.sum(attention[start_i:end_i, start_j:end_j])\n",
        "\n",
        "    return aggregated_attention\n",
        "\n",
        "\n",
        "def visualize_attention(input_sequence, layer=-1, head=0):\n",
        "\n",
        "    outputs = get_model_output(input_sequence)\n",
        "    attention = outputs.attentions[layer][0, head].cpu().numpy()\n",
        "\n",
        "    decoded_tokens = [tokenizer.decode_token(t) for t in tokenizer.encode(input_sequence, add_special_tokens=False, get_move_end_positions=False)]\n",
        "    grouped_tokens = group_tokens(decoded_tokens)\n",
        "\n",
        "    # --> comment to show UCI notation, leave to show SAN move (UCI = c8-f5, SAN = Nf5)\n",
        "    grouped_tokens = re.sub(r'\\d+\\.', '', str(game.mainline_moves())).split()\n",
        "\n",
        "    grouped_attention = aggregate_attention(attention, group_size=2)  # Group size of 2 for pairs\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(grouped_attention, cmap=\"YlOrRd\", xticklabels=grouped_tokens, yticklabels=grouped_tokens)\n",
        "    plt.title(f\"Attention weights for layer {layer+1}, head {head+1}\")\n",
        "    plt.xlabel(\"Key Moves (2 tokens)\")\n",
        "    plt.ylabel(\"Query Moves (2 tokens)\")\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def probe_attention(move_sequence, query_key = 'moves'):\n",
        "    moves = move_sequence.split()\n",
        "    if query_key == 'moves':\n",
        "        vis_att = visualize_attention\n",
        "    else:\n",
        "        vis_att = visualize_attention0\n",
        "\n",
        "    if len(moves) < 3:\n",
        "        print(\"The move sequence is too short for meaningful analysis.\")\n",
        "        return\n",
        "\n",
        "    # Visualize attention for the whole sequence\n",
        "    print(\"Visualizing attention for the entire move sequence:\")\n",
        "\n",
        "    num_layers = 12\n",
        "    num_heads = 12\n",
        "    for i in range(num_heads):\n",
        "        vis_att(move_sequence, 7, i)\n",
        "\n",
        "\n",
        "\n",
        "def generate_average_heatmap(input_sequence, average_over='heads'):\n",
        "    outputs = get_model_output(input_sequence)\n",
        "    num_layers = len(outputs.attentions)\n",
        "    num_heads = outputs.attentions[0].shape[1]\n",
        "\n",
        "    if average_over == 'heads':\n",
        "        # Average over heads for each layer\n",
        "        avg_attention = [torch.mean(layer_output[0], dim=0).cpu().numpy() for layer_output in outputs.attentions]\n",
        "    elif average_over == 'layers':\n",
        "        # Average over layers for each head\n",
        "        avg_attention = [torch.mean(torch.stack([layer[0, head] for layer in outputs.attentions]), dim=0).cpu().numpy()\n",
        "                         for head in range(num_heads)]\n",
        "    else:\n",
        "        raise ValueError(\"average_over must be either 'heads' or 'layers'\")\n",
        "\n",
        "    decoded_tokens = [tokenizer.decode_token(t) for t in tokenizer.encode(input_sequence, add_special_tokens=False, get_move_end_positions=False)]\n",
        "    grouped_tokens = group_tokens(decoded_tokens)\n",
        "\n",
        "    for i, attention in enumerate(avg_attention):\n",
        "        grouped_attention = aggregate_attention(attention, group_size=2)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(grouped_attention, cmap=\"YlOrRd\", xticklabels=grouped_tokens, yticklabels=grouped_tokens)\n",
        "\n",
        "        if average_over == 'heads':\n",
        "            plt.title(f\"Average Attention Weights across Heads for Layer {i+1}\")\n",
        "        else:\n",
        "            plt.title(f\"Average Attention Weights across Layers for Head {i+1}\")\n",
        "\n",
        "        plt.xlabel(\"Key Moves (2 tokens)\")\n",
        "        plt.ylabel(\"Query Moves (2 tokens)\")\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUiM8fliL_wf"
      },
      "outputs": [],
      "source": [
        "# Performing probe attention\n",
        "\n",
        "for g1 in range(1):\n",
        "    g = random.randint(0, 90000)\n",
        "    a = ds['train']['text'][g][1:]\n",
        "    b, c = chop_game_at_random_point(a)\n",
        "\n",
        "    b1 = io.StringIO(b)\n",
        "    game = pgn.read_game(b1)\n",
        "    board = game.board()\n",
        "\n",
        "    move_list = []\n",
        "    for move in game.mainline_moves():\n",
        "        move_list.append(board.uci(move))\n",
        "        board.push(move)\n",
        "\n",
        "    move_sequence = \" \".join(move_list)\n",
        "\n",
        "    '''\n",
        "    print(\"Original sequence:\")\n",
        "    print(b)\n",
        "    print(\"UCI move sequence:\")\n",
        "    print(move_sequence)\n",
        "    '''\n",
        "\n",
        "    probe_attention(move_sequence, query_key = 'moves')\n",
        "\n",
        "    #generate_average_heatmap(move_sequence, average_over='heads')\n",
        "    #generate_average_heatmap(move_sequence, average_over='layers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSohyiNNL_wf"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Part 3\n",
        "# -------------------------------\n",
        "# Probing chess pieces positions\n",
        "# ------------------------------\n",
        "\n",
        "\n",
        "class PiecePositionProbe(torch.nn.Module):\n",
        "    def __init__(self, model_size, num_positions=64):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(model_size, 64)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # Apply the probing classifier to predict the piece positions\n",
        "        piece_logits = self.linear(hidden_states)\n",
        "        # Apply sigmoid to get probabilities\n",
        "        piece_positions_prob = self.sigmoid(piece_logits)\n",
        "\n",
        "        return piece_positions_prob\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.linear.reset_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnKY8AESL_wf"
      },
      "outputs": [],
      "source": [
        "def train_probe(probe, optimizer, criterion, piece, games):\n",
        "    model.eval()\n",
        "    num_epochs = 3\n",
        "    batch_size = 16\n",
        "\n",
        "    if (piece == 'PAWN'):\n",
        "        c_piece = chess.PAWN\n",
        "    elif (piece == 'ROOK'):\n",
        "        c_piece = chess.ROOK\n",
        "    elif (piece == 'KNIGHT'):\n",
        "        c_piece = chess.KNIGHT\n",
        "    elif (piece == 'KING'):\n",
        "        c_piece = chess.KING\n",
        "    elif (piece == 'QUEEN'):\n",
        "        c_piece = chess.QUEEN\n",
        "    else:\n",
        "        c_piece = chess.PAWN\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for g in range(0, 2000, batch_size):\n",
        "            batch_loss = 0\n",
        "            valid_games = 0\n",
        "\n",
        "            for i in range(g, min(g + batch_size, 2000)):\n",
        "                b = chop_game_before_final_moves(str(games[i]))\n",
        "                if b == 'skip':\n",
        "                    continue\n",
        "\n",
        "                b1 = io.StringIO(b)\n",
        "                game = chess.pgn.read_game(b1)\n",
        "                board = game.board()\n",
        "                move_list = []\n",
        "                for move in game.mainline_moves():\n",
        "                    move_list.append(board.uci(move))\n",
        "                    board.push(move)\n",
        "                string_input = \" \".join(move_list)\n",
        "\n",
        "                squares_pieces1 = [1 if(board.piece_type_at(sq) == c_piece) else 0 for sq in chess.SQUARES]\n",
        "                piece_positions = torch.tensor(squares_pieces1).float().unsqueeze(0)  # Shape: [1, 64]\n",
        "\n",
        "                # Get model output\n",
        "                outputs = get_model_output(string_input)\n",
        "                hidden_states = outputs.hidden_states[0]\n",
        "\n",
        "                # Forward pass\n",
        "                output = probe(hidden_states)\n",
        "                output = output[:, -1, :]  # Shape: [1, 64]\n",
        "\n",
        "                loss = criterion(output, piece_positions)\n",
        "                batch_loss += loss.item()\n",
        "                valid_games += 1\n",
        "\n",
        "            if valid_games > 0:\n",
        "                batch_loss /= valid_games\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += batch_loss\n",
        "                num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}: Average Loss = {avg_loss:.4f}\")\n",
        "\n",
        "    print(\"Training completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT7HERP4L_wg"
      },
      "outputs": [],
      "source": [
        "def test_probe(probe, piece, model, tokenizer, test_games, num_test_games=100):\n",
        "    probe.eval()\n",
        "    model.eval()\n",
        "\n",
        "    total_accuracy = 0\n",
        "\n",
        "    if (piece == 'PAWN'):\n",
        "        c_piece = chess.PAWN\n",
        "    elif (piece == 'ROOK'):\n",
        "        c_piece = chess.ROOK\n",
        "    elif (piece == 'KNIGHT'):\n",
        "        c_piece = chess.KNIGHT\n",
        "    elif (piece == 'KING'):\n",
        "        c_piece = chess.KING\n",
        "    elif (piece == 'QUEEN'):\n",
        "        c_piece = chess.QUEEN\n",
        "    else:\n",
        "        c_piece = chess.PAWN\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_test_games):\n",
        "            b = chop_game_before_final_moves(str(test_games[i]))\n",
        "            if b == 'skip':\n",
        "                continue\n",
        "            b1 = io.StringIO(b)\n",
        "            game = chess.pgn.read_game(b1)\n",
        "            board = game.board()\n",
        "            move_list = []\n",
        "            for move in game.mainline_moves():\n",
        "                move_list.append(board.uci(move))\n",
        "                board.push(move)\n",
        "            string_input = \" \".join(move_list)\n",
        "\n",
        "            true_piece_positions = torch.tensor([1 if(board.piece_type_at(sq) == c_piece) else 0 for sq in chess.SQUARES]).float()\n",
        "\n",
        "            outputs = get_model_output(string_input)\n",
        "            hidden_states = outputs.hidden_states[0]\n",
        "\n",
        "            predicted_piece_positions = probe(hidden_states)\n",
        "            predicted_piece_positions = predicted_piece_positions[:, -1, :]  # Shape: [64]\n",
        "            predicted_piece_positions = (predicted_piece_positions > 0.5).float()\n",
        "\n",
        "            accuracy = (predicted_piece_positions == true_piece_positions).float().mean().item()\n",
        "            total_accuracy += accuracy\n",
        "\n",
        "    avg_accuracy = total_accuracy / num_test_games\n",
        "    print(f\"Average accuracy over {num_test_games} test games: {avg_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7oVksyOL_wg"
      },
      "outputs": [],
      "source": [
        "file_path = \"lichess_db1.pgn\"\n",
        "#file_path = \"lichess_db2.pgn\"\n",
        "games = read_pgn_file(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbwvydGeL_wg"
      },
      "outputs": [],
      "source": [
        "vocab_path = \"vocab.txt\"\n",
        "tokenizer = ChessTokenizer(vocab_path)\n",
        "model = GPT2LMHeadModel.from_pretrained('shtoshni/gpt2-chess-uci')\n",
        "initial_state = model.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9Z7Qw07L_wg"
      },
      "outputs": [],
      "source": [
        "#model.load_state_dict(initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LerLTRPeL_wg"
      },
      "outputs": [],
      "source": [
        "# Train probe\n",
        "\n",
        "probe = PiecePositionProbe(model.config.hidden_size, 64)\n",
        "optimizer = torch.optim.Adam(probe.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "piece = 'KING'\n",
        "\n",
        "# --> uncomment to run train\n",
        "#train_probe(probe, optimizer, criterion, piece, games)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_qoPBodL_wg"
      },
      "outputs": [],
      "source": [
        "file_path2 = \"lichess_db2.pgn\"\n",
        "games2 = read_pgn_file(file_path2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l-HCInjL_wg"
      },
      "outputs": [],
      "source": [
        "# Test probe\n",
        "\n",
        "piece = 'KING'\n",
        "\n",
        "# --> uncomment to run test\n",
        "#test_probe(probe, piece, model, tokenizer, games2, len(games2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFn-u0XkL_wg"
      },
      "outputs": [],
      "source": [
        "# PAWN\n",
        "# plain:    Average accuracy over 382 test games: 0.5467\n",
        "# trained:  Average accuracy over 382 test games: 0.8201\n",
        "\n",
        "# ROOK\n",
        "# plain:    Average accuracy over 382 test games: 0.5509\n",
        "# trained:  Average accuracy over 382 test games: 0.9476\n",
        "\n",
        "# KNIGHT\n",
        "# plain:    Average accuracy over 382 test games: 0.5110\n",
        "# trained:  Average accuracy over 382 test games: 0.9714\n",
        "\n",
        "# KING\n",
        "# plain:    Average accuracy over 382 test games: 0.4557\n",
        "# trained:  Average accuracy over 382 test games: 0.9379\n",
        "\n",
        "# QUEEN\n",
        "# plain:    Average accuracy over 382 test games: 0.5714\n",
        "# trained:  Average accuracy over 382 test games: 0.9769\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVfIXeJDL_wg"
      },
      "outputs": [],
      "source": [
        "def save_probe(probe):\n",
        "    current_dir = \"\"\n",
        "    file_path = os.path.join(current_dir, 'king_probe2.pth')\n",
        "    torch.save(probe.state_dict(), file_path)\n",
        "    print(f\"Probe saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avDe9a2JL_wh"
      },
      "outputs": [],
      "source": [
        "#save_probe(probe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rL0BJuQL_wh"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "#probe.load_state_dict(torch.load('king_probe2.pth', map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx9AR7AFL_wh"
      },
      "outputs": [],
      "source": [
        "# --> to reset the probe\n",
        "#probe = PiecePositionProbe(model.config.hidden_size, 64)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
